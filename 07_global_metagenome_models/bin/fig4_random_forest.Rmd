---
title: "Random forest model of Prochlorococcus TBDT abundance"
output: html_notebook
---

```{r}
library(here)
library(tidyverse)
library(tidymodels)
library(performance)
library(ranger)
library(Boruta)
library(recipeselectors)
library(vip)
library(withr)
library(patchwork)
library(rcartocolor)
```

```{r}
tbdt <- read_tsv(here::here("data", "geotraces_tara_combined_imputed.tsv")) %>%
  group_by(sampleID) %>% 
  slice(1) %>%
  ungroup() %>%
  filter(sampleID != "S0468") %>%
  rename(rpkm_tbdt=RPK_prochlorococcus_TBDT,
         rpkm_pro=RPK_total_prochlorococcus_reads) %>%
  mutate(RA=rpkm_tbdt/rpkm_pro)
```

# RECIPE
```{r}
rec <- recipe(RA ~ ., data = tbdt) %>%
  step_mutate(LongCode=as.character(LongCode),
              LongWind=as.character(LongWind)) %>%
  # sets 1 as the floor and imputes values less than 1 between 0 and 1
  step_mutate(RA=ifelse(RA < 1e-05, 1e-05, RA)) %>%
  step_impute_lower(RA) %>% 
  step_rename(climFe=ironDarwin_dissolved_nmol.kg) %>%
  step_rm(lat, lon, LongDesc, contains("imputed_"), 
          matches("pro_LLVII[a-f]"), contains("pel_"),
          bacteria, pro, archaea, eukaryotes, viruses, sar11,
          W, M, rpkm_pro, rpkm_tbdt, RPK_prochlorococcus_marker_median,
          LongCode, LongWind, dcm.max, ocean, hdb_cl,
          contains("Darwin")) %>%
  update_role(sampleID, new_role = "id variable") %>%
  update_role(section, new_role = "id variable") %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors(), threshold = .99) %>%
  step_select_boruta(all_predictors(), outcome = "RA", res="boruta_tune") 

p <- prep(rec, training = tbdt)
bk <- bake(p, new_data = tbdt)
```

# DATA SPLITTING & RESAMPLING
```{r}
with_preserve_seed(splits <-
                     initial_split(tbdt, strata = RA, breaks = 10))

with_preserve_seed(train  <- training(splits))

with_preserve_seed(test   <- testing(splits))
```

# CROSS FOLD SET
```{r}
folds <- vfold_cv(train,
                  v = 10,
                  strata = RA, 
                  breaks = 10)
```

# DEFINE MODELS 
```{r}
cores <- parallel::detectCores()
cores

rf_mod <- 
  rand_forest() %>%
  set_args(   mtry = tune(), 
              min_n = tune(), 
              trees = 1000) %>% 
  set_engine("ranger", 
             num.threads = cores,
             #splitrule = "beta",
             importance = "permutation", 
             replace = FALSE) %>% 
  set_mode("regression")

rf_mod %>%
  parameters()
```

# WORKFLOW
```{r}
wf <- 
  workflow() %>% 
  add_recipe(rec) %>% 
  add_model(rf_mod)
```

# TUNE HYPERPARAMETERS
```{r}
ctrl <- control_grid(extract = identity,
                     verbose = TRUE)

rf_grid <- grid_regular(finalize(mtry(), bk), 
                        finalize(min_n(), bk), 
                        levels = 5)

with_preserve_seed(
  rf_res_boruta <-
    rf_mod %>% 
    tune_grid(
      rec,
      resamples = folds,
      grid = rf_grid,
      control = ctrl,
      #metrics = metric_set(rmse, rsq)
  )
)
```
 

```{r}
rf_res_boruta %>% 
  show_best(metric = "rsq")
```

```{r}
rf_res_boruta %>% 
  show_best(metric = "rmse")
```

```{r}
autoplot(rf_res_boruta)
```

```{r}
rf_best_boruta <- 
  rf_res_boruta %>% 
  select_best(metric = "rsq")
rf_best_boruta
```

# FINAL FIT
After selecting our best model and hyperparameter values, our last step is to fit the final model on all the rows of data not originally held out for testing (both the training and the validation sets combined), and then evaluate the model performance one last time with the held-out test set. Weâ€™ll start by building our parsnip model object again from scratch. We take our best hyperparameter values from our random forest model.

## MODEL
Will run with Boruta
```{r}
final_rf_mod <- 
  rand_forest() %>%
  set_args(mtry = 7, 
              min_n = 2, 
              trees = 1000) %>% 
  set_engine("ranger", 
             num.threads = cores,
             importance = "permutation", 
             #splitrule = "beta",
             replace = FALSE) %>% 
  set_mode("regression")
```

## RECIPE
```{r}
rec
```

## WORKFLOW
```{r}
final_rf_workflow <- 
  workflow() %>% 
  add_recipe(rec) %>% 
  add_model(final_rf_mod)
```

## EXECUTE
```{r}
final_rf_res <-
  final_rf_workflow %>% 
  last_fit(splits)

saveRDS(final_rf_res, here::here("datav2", "ranger_regre_res"))
```

This fitted workflow contains everything, including our final metrics based on the test set. So, how did this model do on the test set? Was the validation set a good estimate of future performance?

```{r}
final_rf_res <- readRDS(here::here("datav2", "ranger_regre_res"))
```

```{r}
final_rf_res %>% 
  collect_metrics()
```

rsq = 0.93
rmse = 0.00017

```{r}
final_rf_res %>%
  collect_predictions()
```

```{r}
final_rf_res %>% 
  pluck(".workflow", 1) %>% 
  pull_workflow_fit() %>% 
  vip(num_features = 59)
```

```{r}
with_preserve_seed(final_rf_prep <- prep(rec))
boruta_obj <- final_rf_prep$steps[[9]]$res
```

```{r}
plot(boruta_obj)
```

```{r}
mean_importance <-
  tibble(
    importance = boruta_obj$ImpHistory %>% colMeans(),
    PC = colnames(boruta_obj$ImpHistory)
  ) %>%
  mutate(importance = ifelse(PC == "PC18",
                             mean(boruta_obj$ImpHistory[, 18][!is.infinite(boruta_obj$ImpHistory[, 18])]),
                             importance))
```

```{r}
mean_importance %>% filter(importance > 4) %>% summarize(s=sum(importance))
```

```{r}
mean_importance %>% filter(importance > 8.5) %>% summarize(s=sum(importance))
```

# PCA
[Correlation between an original variable and a principal component](https://stats.stackexchange.com/q/253718)

[How to find which variables are most correlated with the first principal component?](https://stats.stackexchange.com/q/115032)

"the covariance matrix of standardized variables (i.e. z scores) equals the correlation matrix."

[Which variables explain which PCA components, and vice versa?](https://stats.stackexchange.com/a/133176)

[PCA on correlation or covariance?](https://stats.stackexchange.com/q/53)

[Standardized betas for relative importance](https://stats.stackexchange.com/a/29782)

https://stats.stackexchange.com/a/25707

## OUTPUT OF PRCOMP FUNCTION
1. sdev = the standard deviations of the principal components
2. rotation = the matrix of variable loadings (columns are eigenvectors)
3. center = the variable means (means that were substracted)
4. scale = the variable standard deviations (the scaling applied to each variable )
5. x = The coordinates of the individuals (observations) on the principal components.
```{r}
with_preserve_seed(pca_input <- recipe(RA ~ ., data = tbdt) %>%
  step_mutate(LongCode=as.character(LongCode),
              LongWind=as.character(LongWind)) %>%
  # sets 1 as the floor and imputes values less than 1 between 0 and 1
  step_mutate(RA=ifelse(RA < 1e-05, 1e-05, RA)) %>%
  step_impute_lower(RA) %>%  
  step_rename(climFe=ironDarwin_dissolved_nmol.kg) %>%
  step_rm(lat, lon, LongDesc, contains("imputed_"), 
          matches("pro_LLVII[a-f]"), contains("pel_"),
          bacteria, pro, archaea, eukaryotes, viruses, sar11,
          W, M, rpkm_pro, rpkm_tbdt, RPK_prochlorococcus_marker_median,
          LongCode, LongWind, dcm.max, ocean, hdb_cl,
          contains("Darwin")) %>%
  update_role(sampleID, new_role = "id variable") %>%
  update_role(section, new_role = "id variable") %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors()) %>%
  prep(training = tbdt) %>% 
  bake(tbdt) %>%
  select(-section, -sampleID, -RA))

with_preserve_seed(pca_res <- prcomp(pca_input))
```


## GETTING R2 FOR EACH VARIABLE AND PC
PC $i$ is associated with an eigenvector $\mathrm{V}_{i}$ of the correlation matrix and the corresponding eigenvalue $s_{i}$. A loadings vector $\mathrm{L}_{i}$ is given by $\mathrm{L}_{i} = \sqrt{s_{i}}\times\mathrm{V}_{i}$. Its elements are correlations of this PC with the respective original variables.

Note that eigenvectors $\mathrm{V}_{i}$ and loadings $\mathrm{L}_{i}$ are two different things! In R, eigenvectors are confusingly called "loadings";  be careful: their elements are not the right correlations.

### EIGENVALUES
```{r}
evals <- pca_res$sdev^2
variance <- evals * 100/sum(evals)
cumvar <- cumsum(variance)

eigensummary <- tibble(PC = colnames(pca_res$rotation),
                       eigenvalue = evals, 
                       variance.percent = variance, 
                       cumulative.variance.percent = cumvar) %>%
  mutate(PC=case_when(PC=="PC1" ~ "PC01",
                      PC=="PC2" ~ "PC02",
                      PC=="PC3" ~ "PC03",
                      PC=="PC4" ~ "PC04",
                      PC=="PC5" ~ "PC05",
                      PC=="PC6" ~ "PC06", 
                      PC=="PC7" ~ "PC07",
                      PC=="PC8" ~ "PC08",
                      PC=="PC9" ~ "PC09",
                      TRUE ~ PC)) 

eigensummary
```

### LOADINGS
This is called `rotation` and is the $\mathrm{V}$ matrix from above. $\mathrm{V}_{1}$ is the eigenvector of the first PC and so on...

The PCA was done on a correlation matrix (not covariance) because we normalized the variables to zero mean and 1 standard deviation. Thus, the eigenvector matrix $\mathrm{V}$ is actually the correlation matrix. [See here for why.](https://stats.stackexchange.com/a/115130). To get the variance explained ($R^{2}$) of the PC by each variable then you just take the square of the eigenvector matrix $\mathrm{V}$.

```{r}
pca_res_r2 <- data.frame(pca_res$rotation^2)

colSums(pca_res_r2)
```

## EXPLAINING VARIABLE VARIANCE BY PCS
How much of the variance of a given original variable is explained by a given subset of PCs?

https://stats.stackexchange.com/a/133176

Because PCs are orthogonal (i.e. uncorrelated), one can simply add up individual R2 values (see Q1) to get the global R2 value

```{r}
#PCs selected by Boruta
pc_top10 <- c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06", "PC07", "PC08", "PC10", "PC13")

pc_order_top10 <- mean_importance %>% filter(PC %in% pc_top10) %>% arrange(desc(importance)) %>% slice(1:10) %>% pull(PC)

pca_res_r2_l <- pca_res_r2 %>%
  rownames_to_column(var="variable") %>%
  rename(PC01=PC1, PC02=PC2, PC03=PC3, PC04=PC4, PC05=PC5, PC06=PC6, PC07=PC7, PC08=PC8, PC09=PC9) %>%
  pivot_longer(PC01:PC27, names_to="PC", values_to="R2") %>%
  filter(PC %in% pc_keep) %>%
  group_by(variable) %>%
  summarize(total_var_exp=sum(R2)) %>%
  arrange(desc(total_var_exp))

pca_res_r2_l
```

## EXPLAINING PC VARIANCE BY ORIGINAL VARIABLES
How much of the variance of a given PC is explained by a given subset of original variables?  

https://stats.stackexchange.com/a/133176

Basically you need to regress the selected variables against the PC values and get the R2 from that.

```{r}
tmp <- data.frame(pca_res$x) %>%
  mutate(sampleID = pull(tbdt, sampleID)) %>%
  left_join(., tbdt) %>%
  rename(PC01=PC1, PC02=PC2, PC03=PC3, PC04=PC4, PC05=PC5, PC06=PC6, PC07=PC7, PC08=PC8, PC09=PC9)

# this tells for example that dcm_depth, pro_LLI, and iron explained 60% of variance in PC06
summary(lm(PC06 ~ dcm_depth + pro_LLI + iron_dissolved_nmol.kg, data=tmp))

# 69%
summary(lm(PC04 ~ chla_norm + pro_LLI, data=tmp))

# 54%
summary(lm(PC10 ~ salinity_dissolved_PSS.1978 + iron_dissolved_nmol.kg + nitrite_dissolved_umol.kg, data=tmp))
```

# PLOTTING

## Relationship between PCs and TBDT relative abundance
```{r}
#PCs selected by Boruta
pc_keep <- c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06", "PC07", "PC08", "PC09", "PC10", "PC11", "PC12", "PC13", "PC14", "PC15", "PC16", "PC17", "PC20", "PC21", "PC22")

pc_order <- mean_importance %>% filter(PC %in% pc_keep) %>% arrange(desc(importance)) %>% slice(1:10) %>% pull(PC)

pPCRA <- data.frame(pca_res$x) %>%
  mutate(sampleID = pull(tbdt, sampleID)) %>%
  left_join(., select(tbdt, sampleID, RA, ocean)) %>%
  rename(PC01=PC1, PC02=PC2, PC03=PC3, PC04=PC4, PC05=PC5, PC06=PC6, PC07=PC7, PC08=PC8, PC09=PC9) %>%
  pivot_longer(PC01:PC27, names_to="PC") %>%
  filter(PC %in% pc_order) %>%
  mutate(PC=factor(PC, levels=pc_order)) %>% 
  ggplot() +
    geom_point(aes(x=value, y=RA, color=ocean), shape=16, size=1, alpha=0.5) +
    facet_wrap(~ PC, scales="free_x") +
    scale_y_sqrt() +
    scale_color_brewer(palette="Dark2", direction=-1) + 
    theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())

ggsave(here::here("figs", "pPCRA.svg"), plot=pPCRA,
       device="svg", units="cm", height=14, width=20)
```

## Main text Fig 4
```{r}
#PCs selected by Boruta
pc_keep <- c("PC01", "PC02", "PC03", "PC04", "PC05", "PC06", "PC07", "PC08", "PC09", "PC10", "PC11", "PC12", "PC13", "PC14", "PC15", "PC16", "PC17", "PC20", "PC21", "PC22")

pc_order <- mean_importance %>% filter(PC %in% pc_keep) %>% arrange(desc(importance)) %>% pull(PC)
  
# weight R2 by PC importance from boruta. Sum all weighted R2 to get variable ranking 
total_var_explained <- left_join(pca_res_r2_l, mean_importance) %>%
  filter(PC %in% pc_keep) %>%
  mutate(var_expl=importance*R2) %>% 
  group_by(variable) %>%
  summarize(cum_importance=sum(var_expl))

# heatmap of unweighted variable R2 with PC.
# PC orderd by boruta importance
# variable ordered by weighted R2 from above
hmap <- left_join(pca_res_r2_l, total_var_explained) %>%
  filter(PC %in% pc_keep) %>%
  mutate(PC=factor(PC, levels=pc_order)) %>%
  mutate(variable=fct_reorder(variable, cum_importance, .desc = F)) %>%
  ggplot(aes(x=PC, y=variable, fill=R2)) + 
  geom_tile() +
  labs(x = "", y = "", fill = "") + 
  scale_fill_viridis_c() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.margin = unit(c(0,0,0,0), "cm"),
        plot.background=element_blank())

# barplot of Boruta variable importance
boruta <- mean_importance %>%
  filter(PC %in% pc_keep) %>%
  mutate(PC=factor(PC, levels=pc_order)) %>%
  ggplot() +
  geom_bar(aes(x = PC, y = importance), stat = "identity") +
  labs(x = "", y = "", fill = "") + #y = RF variable importance
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.margin = unit(c(0,0,0,0), "cm"),
        plot.background=element_blank())

# total variance of metadata explained by each PC
vexp <-eigensummary %>%
  filter(PC %in% pc_keep) %>%
  mutate(PC=factor(PC, levels=pc_order)) %>%
  ggplot() +
  geom_bar(aes(x = PC, y = variance.percent), stat = "identity") +
  labs(y = "", fill = "") +
  scale_y_reverse() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        plot.margin = unit(c(0,0,0,0), "cm"),
        plot.background=element_blank())

fig4 <- (boruta / hmap / vexp) + plot_layout(nrow=3, ncol=1, widths = c(1,1,1), heights=c(0.3, 1, 0.3), guides = 'collect')
```

```{r}
ggsave(here::here("figs", "hmap_final.svg"), plot=fig4,
       device="svg", units="cm", height=15, width=15)
```

```{r}
fig4
```

